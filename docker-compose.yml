services:
  nginx:
    image: nginx:alpine
    container_name: web_server
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./frontend:/usr/share/nginx/html
    networks:
      - frontend-network
    depends_on:
      - backend
    restart: unless-stopped

  backend:
    build: ./backend
    container_name: backend
    env_file: .env.docker
    volumes:
      - ./backend:/app
    networks:
      - backend-network
      - frontend-network
    depends_on:
      - db
      - ai-model
    restart: unless-stopped

  # grader:
  #   build: ./grader
  #   container_name: grader
  #   ports:
  #     - "8001:8001"
  #   volumes:
  #     - ./fine-tuned-model:/app/fine-tuned-model
  #   environment:
  #     - MODEL_PATH=/app/fine-tuned-model
  #   networks:
  #     - backend-network
  #   deploy:
  #     resources:
  #       devices:
  #         - driver: nvidia
  #           count: 1
  #           capabilities: [gpu]

  grader:
    build: ./grader  # Path to the directory containing Dockerfile
    container_name: grader
    # ports:
      # - "8000:8000"  # FastAPI REST API
      # - "11434:11434"  # Ollama API
    volumes:
      - ollama_data:/root/.ollama  # Persistent storage for Ollama models
    environment:
      - OLLAMA_MODEL=llama3.2  # Default model to use
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # Enable GPU support
    networks:
      - backend-network

  db:
    image: mysql:8.0
    container_name: db
    env_file: .env.docker
    volumes:
      - db_data:/var/lib/mysql
    networks:
      - backend-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      timeout: 20s
      retries: 10
volumes:
  db_data:
  ollama_data:

networks:
  frontend-network:
    driver: bridge
  backend-network:
    driver: bridge